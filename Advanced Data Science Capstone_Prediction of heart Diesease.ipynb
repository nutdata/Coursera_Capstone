{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction of heart diesease"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Natthapol Jinavanich</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Use Case identification:_ find any trends in heart data to predict certain cardiovascular events or find any clear indications of heart health."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Source: https://www.kaggle.com/ronitf/heart-disease-uci (Initial Data Source: https://archive.ics.uci.edu/ml/datasets/Heart+Disease)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Attribute Information:\n",
    "\n",
    "- age\n",
    "- sex\n",
    "- chest pain type (4 values)\n",
    "- resting blood pressure\n",
    "- serum cholestoral in mg/dl\n",
    "- fasting blood sugar > 120 mg/dl\n",
    "- resting electrocardiographic results (values 0,1,2)\n",
    "- maximum heart rate achieved\n",
    "- exercise induced angina\n",
    "- oldpeak = ST depression induced by exercise relative to rest\n",
    "- the slope of the peak exercise ST segment\n",
    "- number of major vessels (0-3) colored by flourosopy\n",
    "- thal: 3 = normal; 6 = fixed defect; 7 = reversable defect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as st\n",
    "%matplotlib inline\n",
    "import types\n",
    "from botocore.client import Config\n",
    "import ibm_boto3\n",
    "\n",
    "# preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "\n",
    "# models\n",
    "import sklearn\n",
    "from sklearn.linear_model import LogisticRegression, Perceptron, RidgeClassifier, SGDClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# NN models\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras import optimizers\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# import warnings filter\n",
    "from warnings import simplefilter\n",
    "# ignore all future warnings\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "print('Python: {}'.format(sys.version))\n",
    "print('Pandas: {}'.format(pd.__version__))\n",
    "print('Numpy: {}'.format(np.__version__))\n",
    "print('Sklearn: {}'.format(sklearn.__version__))\n",
    "print('Matplotlib: {}'.format(matplotlib.__version__))\n",
    "print('Keras: {}'.format(keras.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import data\n",
    "df = pd.read_csv(\"heart.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data quality check\n",
    "df.isnull().sum()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the number of unique values in target variable\n",
    "df['target'].nunique()\n",
    "# Caunt the unique values in target variable\n",
    "df['target'].value_counts()\n",
    "# Check the distribution of the unique values in target variable\n",
    "df.groupby('sex')['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Histogram plot\n",
    "df.hist(figsize = (12, 12))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking all discreate values for sepearate analysis (boxplot)\n",
    "fig, axes = plt.subplots(ncols=8,figsize=(20,3))\n",
    "sns.boxplot(x='target',y='ca',data=df, palette='winter', ax=axes[0])\n",
    "axes[0].set_title('Chest Pain vs Target distribution')\n",
    "\n",
    "sns.boxplot(x='target',y='cp' ,data=df, palette='winter', ax=axes[1])\n",
    "axes[1].set_title(\"fbs vs Target \")\n",
    "\n",
    "sns.boxplot(x='target',y='exang' ,data=df, palette='winter', ax=axes[2])\n",
    "axes[2].set_title(\"restecg vs Target distribution\")\n",
    "\n",
    "sns.boxplot(x='target',y='fbs' ,data=df, palette='winter', ax=axes[3])\n",
    "axes[3].set_title(\"thalach vs Target \")\n",
    "\n",
    "sns.boxplot(x='target',y='restecg' ,data=df, palette='winter', ax=axes[4])\n",
    "axes[4].set_title(\"slope vs Target distribution\")\n",
    "\n",
    "sns.boxplot(x='target',y='sex' ,data=df, palette='winter', ax=axes[5])\n",
    "axes[5].set_title(\"chol vs Target \")\n",
    "\n",
    "sns.boxplot(x='target',y='slope' ,data=df, palette='winter', ax=axes[6])\n",
    "axes[6].set_title(\"thal vs Target \")\n",
    "\n",
    "sns.boxplot(x='target',y='thal' ,data=df, palette='winter', ax=axes[7])\n",
    "axes[7].set_title(\"thal vs Target \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rest_data = ['age', 'chol', 'oldpeak', 'thalach', 'trestbps', 'target' ]\n",
    "sns.pairplot(df[rest_data], kind='scatter', diag_kind='hist')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pair plot by group target\n",
    "rest_data_vs_target = df[rest_data]\n",
    "sns.pairplot(rest_data_vs_target, hue=\"target\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking correlation between target variable and each attributes\n",
    "correlation = df.corr()\n",
    "correlation['target'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,12))\n",
    "plt.title('Correlation Heatmap of Heart Disease Dataset')\n",
    "a = sns.heatmap(correlation, cmap='YlGnBu', square=True, annot=True, fmt='.2f', linecolor='green')\n",
    "a.set_xticklabels(a.get_xticklabels(), rotation=90)\n",
    "a.set_yticklabels(a.get_yticklabels(), rotation=30)           \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling (Machine Learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's Start train and test different models\n",
    "target_name = 'target'\n",
    "data_target = df[target_name]\n",
    "data = df.drop([target_name], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train/Test-80/20\n",
    "train, test, target, target_test = train_test_split(data, data_target, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(train, target)\n",
    "acc_log = round(logreg.score(train, target) * 100, 2)\n",
    "acc_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_test_log = round(logreg.score(test, target_test) * 100, 2)\n",
    "acc_test_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Machines \n",
    "\n",
    "svc = SVC()\n",
    "svc.fit(train, target)\n",
    "acc_svc = round(svc.score(train, target)*100, 2)\n",
    "acc_svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_test_svc = round(svc.score(test, target_test) * 100, 2)\n",
    "acc_test_svc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Support Vector Machines (SVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Support Vector Machines (SVC)\n",
    "\n",
    "linear_svc = LinearSVC(dual=False)  # dual=False when n_samples > n_features.\n",
    "linear_svc.fit(train, target)\n",
    "acc_linear_svc = round(linear_svc.score(train, target) * 100, 2)\n",
    "acc_linear_svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_test_linear_svc = round(linear_svc.score(test, target_test) * 100, 2)\n",
    "acc_test_linear_svc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k-Nearest Neighbors algorithm (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k-Nearest Neighbors algorithm (KNN)\n",
    "\n",
    "knn = GridSearchCV(estimator=KNeighborsClassifier(), param_grid={'n_neighbors': [2, 3]}, cv=10).fit(train, target)\n",
    "acc_knn = round(knn.score(train, target) * 100, 2)\n",
    "print(acc_knn, knn.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_test_knn = round(knn.score(test, target_test) * 100, 2)\n",
    "acc_test_knn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian Naive Bayes\n",
    "\n",
    "gaussian = GaussianNB()\n",
    "gaussian.fit(train, target)\n",
    "acc_gaussian = round(gaussian.score(train, target) * 100, 2)\n",
    "acc_gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_test_gaussian = round(gaussian.score(test, target_test) * 100, 2)\n",
    "acc_test_gaussian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perceptron\n",
    "\n",
    "perceptron = Perceptron()\n",
    "perceptron.fit(train, target)\n",
    "acc_perceptron = round(perceptron.score(train, target) * 100, 2)\n",
    "acc_perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_test_perceptron = round(perceptron.score(test, target_test) * 100, 2)\n",
    "acc_test_perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stochastic Gradient Descent\n",
    "\n",
    "sgd = SGDClassifier()\n",
    "sgd.fit(train, target)\n",
    "acc_sgd = round(sgd.score(train, target) * 100, 2)\n",
    "acc_sgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_test_sgd = round(perceptron.score(test, target_test) * 100, 2)\n",
    "acc_test_sgd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree Classifier\n",
    "\n",
    "decision_tree = DecisionTreeClassifier()\n",
    "decision_tree.fit(train, target)\n",
    "acc_decision_tree = round(decision_tree.score(train, target) * 100, 2)\n",
    "acc_decision_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_test_decision_tree = round(decision_tree.score(test, target_test) * 100, 2)\n",
    "acc_test_decision_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "\n",
    "random_forest = GridSearchCV(estimator=RandomForestClassifier(), param_grid={'n_estimators': [100, 300]}, cv=5).fit(train, target)\n",
    "random_forest.fit(train, target)\n",
    "acc_random_forest = round(random_forest.score(train, target) * 100, 2)\n",
    "print(acc_random_forest,random_forest.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_test_random_forest = round(random_forest.score(test, target_test) * 100, 2)\n",
    "acc_test_random_forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ridge Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_classifier = RidgeClassifier()\n",
    "ridge_classifier.fit(train, target)\n",
    "acc_ridge_classifier = round(ridge_classifier.score(train, target) * 100, 2)\n",
    "acc_ridge_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_test_ridge_classifier = round(ridge_classifier.score(test, target_test) * 100, 2)\n",
    "acc_test_ridge_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = pd.DataFrame({\n",
    "    'Model': ['Logistic Regression', 'Support Vector Machines', 'Linear SVC', \n",
    "              'k-Nearest Neighbors', 'Naive Bayes', 'Perceptron', \n",
    "              'Stochastic Gradient Decent', 'Decision Tree Classifier', 'Random Forest', \n",
    "              'RidgeClassifier'],\n",
    "    \n",
    "    'Score_train': [acc_log, acc_svc, acc_linear_svc, \n",
    "                    acc_knn, acc_gaussian, acc_perceptron, \n",
    "                    acc_sgd, acc_decision_tree, acc_random_forest, \n",
    "                    acc_ridge_classifier],\n",
    "    \n",
    "    'Score_test': [acc_test_log, acc_test_svc, acc_test_linear_svc, \n",
    "                   acc_test_knn, acc_test_gaussian, acc_test_perceptron, \n",
    "                   acc_test_sgd, acc_test_decision_tree, acc_test_random_forest, \n",
    "                   acc_test_ridge_classifier]\n",
    "                    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.sort_values(by=['Score_test', 'Score_train'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling (Deep learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create X and Y datasets for training\n",
    "from sklearn import model_selection\n",
    "X = np.array(df.drop(['target'], 1))\n",
    "y = np.array(df['target'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the data to categorical labels\n",
    "\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "Y_train = to_categorical(y_train, num_classes=None)\n",
    "Y_test = to_categorical(y_test, num_classes=None)\n",
    "print (Y_train.shape)\n",
    "print (Y_train[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building and Training the Neural Network\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# define a function to build the keras model\n",
    "def create_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(16, input_dim=13, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(8, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    \n",
    "    # compile model\n",
    "    adam = Adam(lr=0.001)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = create_model()\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model to the training data\n",
    "history=model.fit(X_train, Y_train, validation_data=(X_test, Y_test),epochs=200, batch_size=10, verbose = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Model accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Losss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert into binary classification problem - heart disease or no heart disease\n",
    "Y_train_binary = y_train.copy()\n",
    "Y_test_binary = y_test.copy()\n",
    "\n",
    "Y_train_binary[Y_train_binary > 0] = 1\n",
    "Y_test_binary[Y_test_binary > 0] = 1\n",
    "\n",
    "print(Y_train_binary[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a new keras model for binary classification\n",
    "def create_binary_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(16, input_dim=13, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(8, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    # Compile model\n",
    "    adam = Adam(lr=0.001)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "binary_model = create_binary_model()\n",
    "\n",
    "print(binary_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history=binary_model.fit(X_train, Y_train_binary, validation_data=(X_test, Y_test_binary), epochs=200, batch_size=10, verbose = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# Model accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Losss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate classification report using predictions for categorical model\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "categorical_pred = np.argmax(model.predict(X_test), axis=1)\n",
    "\n",
    "print('Results for Categorical Model')\n",
    "print(accuracy_score(y_test, categorical_pred))\n",
    "print(classification_report(y_test, categorical_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate classification report using predictions for categorical model\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "# generate classification report using predictions for binary model \n",
    "binary_pred = np.round(binary_model.predict(X_test)).astype(int)\n",
    "\n",
    "print('Results for Binary Model')\n",
    "print(accuracy_score(Y_test_binary, binary_pred))\n",
    "print(classification_report(Y_test_binary, binary_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
